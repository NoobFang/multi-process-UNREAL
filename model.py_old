# -*- coding: utf-8 -*-
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf
import keras
import numpy as np

from constants import *

# weight initialization based on muupan's code
# https://github.com/muupan/async-rl/blob/master/a3c_ale.py
def fc_initializer(input_channels, dtype=tf.float32):
  def _initializer(shape, dtype=dtype, partition_info=None):
    d = 1.0 / np.sqrt(input_channels)
    return tf.random_uniform(shape, minval=-d, maxval=d)
  return _initializer


def conv_initializer(kernel_width, kernel_height, input_channels, dtype=tf.float32):
  def _initializer(shape, dtype=dtype, partition_info=None):
    d = 1.0 / np.sqrt(input_channels * kernel_width * kernel_height)
    return tf.random_uniform(shape, minval=-d, maxval=d)
  return _initializer



class UnrealNetwork(object):
  def __init__(self, ob_shape, ac_shape):
    self.ob_shape = ob_shape
    self.action_n = ac_shape
    # input placeholders
    self.image_input = tf.placeholder(dtype=tf.float32, [None]+self.ob_shape)
    self.last_action_reward_input = tf.placeholder(dtype=tf.float32, [None, self.action_n+1])
    self.base_init_lstm_s0 = tf.placeholder(dtype=tf.float32, [1,256])
    self.base_init_lstm_s1 = tf.placeholder(dtype=tf.float32, [1,256])
    self.lstm_cell = tf.contrib.rnn.BasicLSTMCell(256, state_is_tuple=True)
    self.create_a3c()
    self.reset_lstm_state()

  def create_a3c(self):
    
    self.conv_output = self.base_conv_layers(self.image_input)
    self.base_init_lstm_state = tf.contrib.rnn.LSTMStateTuple(self.base_init_lstm_s0,
                                                              self.base_init_lstm_s1)
    self.lstm_output, self.lstm_state = self.base_lstm_layer(self.conv_output,
                                                             self.last_action_reward_input,
                                                             self.base_init_lstm_state)
    self.base_pi = self.base_policy_layers(self.lstm_output)
    self.base_v = self.base_value_layers(self.lstm_output)

  def create_pc(self):
    

  def create_rp(self)

  def create_vr(self)
  
  def reset_lstm_state(self):
    self.base_lstm_state_out = tf.contrib.rnn.LSTMStateTuple(np.zeros([1,256]),
                                                             np.zeros([1,256]))
      
  def base_conv_layers(self, image_input, reuse=False):
    conv1 = tf.layers.conv2d(inputs=image_input, filters=16, kernel_size=[8,8,3], strides=(4,4),
                            kernel_initializer=conv_initializer, activation=tf.nn.relu)
    conv2 = tf.layers.conv2d(inputs=conv1, filters=32, kernel_size=[4,4,16], strides=(2,2),
                            kernel_initializer=conv_initializer, activation=tf.nn.relu)
    return conv2

  def base_lstm_layer(self, conv_out, last_action_reward_input, init_image_input, reuse=False):
    conv_flat = tf.reshape(conv_out, [-1, 2592])
    conv_fc = tf.layers.dense(conv_flat, units=256, activation=tf.nn.relu,
                              kernel_initializer=fc_initializer)
    
    step_size = tf.shape(conv_fc)[:1]
    lstm_input = tf.concat([conv_fc, last_action_reward_input], axis=1)
    lstm_input = tf.reshape(lstm_input, [1,-1,256+self.action_n+1])
    lstm_output, lstm_state = tf.nn.dynamic_rnn(self.lstm_cell, lstm_input,
                                                initial_state=init_image_input,
                                                sequence_length=step_size)
    lstm_output = tf.reshape(lstm_output, [-1, 256])

    return lstm_output, lstm_state

  def base_policy_layer(self, lstm_output, reuse=False):
    logits = tf.layers.dense(lstm_output, units=self.action_n,
                             kernel_initializer=fc_initializer)
    pi = tf.nn.softmax(logits)
    return pi

  def base_value_layer(self, lstm_output, reuse=False):
    v_ = tf.layers.dense(lstm_output, units=1, kernel_initializer=fc_initializer)
    return tf.reshape(v_, [-1])

  def pc_deconv_layers(self, lstm_output, reuse=False):
    # size is 7*7 in paper, but after deconv, they say the result is 20*20, which
    # is not consistent. use 9*9 to make the result size remain 20*20
    fc1 = tf.layers.dense(lstm_output, units=9*9*32, activation=tf.nn.relu,
                          kernel_initializer=fc_initializer)
    fc1 = tf.reshape(fc1, [-1, 9, 9, 32])
    # dueling network for value and advantage
    deconv_v = tf.layers.conv2d_transpose(fc1, filters=1, kernel_size=[4,4], strides=(2,2))
    deconv_a = tf.layers.conv2d_transpose(fc1, filters=self.action_n, kernel_size=[4,4], strides=(2,2))
    a_mean = tf.reduce_mean(deconv_a, axis=3, keep_dims=True)
    pc_q = deconv_v + deconv_a - a_mean
    pc_q_max = tf.reduce_max(pc_q, axis=3)

    return pc_q, pc_q_max

  